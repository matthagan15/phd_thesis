\chapter{Introduction}

\section{Motivation}

In everyday life we interact with temperature on an intuitive sense: hot objects cool down, refrigerators consume energy to keep things cold, and the winters here in Toronto suck all possible heat out of every living thing. We typically don't think too much about how these systems equilibrate, we now that there are convection currents in liquids that transport heat, that solids, metals in particular, conduct heat naturally and that radiation can transmit heat, which occurs in microwaves and from sunlight. If you are cooking a roast and want to know if it's done, you just stick the thermometer in and wait a few seconds for it to equilibrate. You don't need for the thermometer to meet some kind of interaction model between the thermometer and the food, it just equilibrates given enough time. 

This intuitive understanding breaks down at the quantum level. For starters, to observe delicate quantum effects experimentalists will typically try to isolate their desired system as much as possible from the environment, which can decohere sensitive wavefunctions. When the system is completely isolated from the environment, what does ``equilibrium'' even refer to? One of the leading answers to this question says that for large systems, sufficiently ``random looking'' Hamiltonians can appear to be in thermal equilibrium to local observables. A large enough, random enough system can act as it's own bath to small subsystems. The codification of these conditions is known as the Eigenstate Thermalization Hypothesis (ETH), which is yet to be proven for all possible systems (hence the name Hypothesis).

The picture of thermalization that we address is an intermediate model of the two previously mentioned, where instead of modeling infinite baths or having no baths at all we instead consider a very tiny environment that is consistently refreshed. This model, known as the Repeated Interactions (RI) model, is appealing for many different reasons. For starters, since the environment is small enough we can often compute the effects on the system directly. So far, physicists have mostly studied this model for small systems in which these interactions can be explicitly modeled, such as 2 or 3 level systems. Oftentimes the interaction model between these small systems and the environment is chosen to lead to a thermal state on the system.

We extend the Repeated Interactions model to arbitrary non-degenerate systems via a randomized interaction. This not only extends the validity of the Repeated Interactions model greatly, thus providing a physically plausible model for thermalization, but also provides an algorithm for preparing thermal states on digital quantum computers. We are able to prove both correctness, meaning the output of the algorithm is $\epsilon$ close to the thermal state, and bound the runtime in the weak coupling limit. This runtime bound is interesting in it's own right as bounding the runtime of the algorithm in the ground state limit is difficult, however in our scenario the runtime bound becomes completely explicit. 

Although the resulting quantum channel we develop almost directly resembles the Repeated Interactions framework, the route we took was inspired entirely by the classical sampling algorithm called Hamiltonian Monte Carlo (HMC). HMC takes the original Metropolis-Hastings algorithm, which involves a filtered random walk over the state space, and modifies the random walk steps to instead simulate time evolution under Hamiltonian dynamics. This modification drastically improved the original algorithm's scaling with respect to the dimension of the problem and offered less correlated samples empirically. This thesis can be viewed as an effort to extend this algorithm, which is heavily inspired by physics, to the realm of quantum computing. 

This thesis is organized as follows. The rest of this chapter will be devoted to preliminary discussion on relevant quantum computing topics, namely how to implement time evolution operators for Pauli sum Hamiltonians. The next chapter is devoted to improvements in basic product formula techniques via a composite or partially randomized compilation scheme. We then utilize these results in Chapter \ref{ch:tsp} to develop our quantum algorithm for preparing thermal states. To complement our analytic discussions we provide extensive numeric evidence in support of our routines. 

\section{Introduction to Product Formulae}
One of the key themes in this thesis is that time dynamics can be used to generate thermal states. In this section we introduce one of the most straightforward methods for implementing time independent Hamiltonian evolution on a quantum computer. We will not introduce basic quantum computing preliminaries, such as universality and various gate sets, but we will take strides to reduce the algorithms to primitives that are as simple as possible. 

Quantum mechanics starts with the notion of a Hilbert space. Oftentimes problems can become much clearer once one can clearly identify and manipulate the Hilbert space under investigation. We will work with relatively straightforward Hilbert spaces in this thesis, those consisting of $n$ qubits $\mathcal{H} = \CC^{2} \otimes \CC^2 \otimes \ldots \otimes \CC^2 = \CC^{2^n}$. Watrous prefers the term ``Complex Euclidean Spaces'' for these finite dimensional Hilbert spaces. A state $\ket{\psi} \in \mathcal{H}$ is an $L_2$ normalized vector and given a Hamiltonian $H$ that dictates the dynamics of the system, the time evolution is given by the time independent Schrodinger equation
\begin{equation}
    i \hbar \frac{\partial}{\partial t} \ket{\psi(t)} = H(t) \ket{\psi(t)}.
\end{equation}
For the rest of this thesis $\hbar = 1$. 

Our use of qubit Hilbert spaces gives us access to the Pauli operators $I_i, X_i, Y_i, Z_i$ for each qubit $i$, which we can then string together to form a Pauli string, here is an example on 4 qubits $P = X_1 \otimes I_2 \otimes Y_3 \otimes Z_4$. Typically we will drop the tensor product symbol $\otimes$ and drop the identity factors, so the previous example will be written as $P = X_1 Y_3 Z_4$. A useful fact about Pauli operators is that they can be exponentiated fairly easily due to the identity $e^{i \theta P} = \cos(\theta) I + i \sin(\theta) P$. We now will show how these rotations can be implemented given only single qubit rotations and CNOT gates. Here is a basic example of how to do a two qubit rotation $e^{i \theta Z \otimes Z}$.
\begin{table}[h]
    \[
    \begin{array}{c c c} 
        \Qcircuit @C=1em @R=.7em {
            & \ctrl{2} & \qw      & \qw                & \qw      & \ctrl{2} & \qw \\
            & \qw      & \ctrl{1} & \qw                & \ctrl{1} & \qw      & \qw\\
            & \targ    & \targ    & \gate{R_Z(2 \theta)} & \targ    & \targ    & \qw
        } &  = & \Qcircuit @C=1em @R = 0.7em {
             & \gate{e^{i \theta Z_1 Z_2}} & \qw
        }
    \end{array}
    \]
    \caption{$Z_1 Z_2$ rotation.}
\end{table}
This is a slightly abstracted circuit, as arbitrary angle $Z$ rotations are not typical circuits that real quantum computers can do. To further compile this, one would need to decompose the single qubit $Z$ rotation into some universal gate set, typically Clifford + T, using an algorithm such as the Ross-Sellinger single qubit rotation algorithm. For this thesis we will assume access to single qubit rotations and CNOT gates as our universal gate set. 

To extend this to arbitary $n$ qubit Paulis with possibly $X$ or $Y$ Paulis as well we can repeat the same circuit but with a change of basis. With the basic circuit identities that $X = H Z H$ and $Y = S Z S^\dagger$. We can then change basis from the computation basis states to those of the Pauli we are interested in, do the computation in the $Z$ basis, and then change back to the computation basis. For instance, here is how we could do the rotation $e^{i X_1 Y_2 Z_3 \theta}$
\begin{table}[h]
\[
\begin{array}{c}
    \Qcircuit @C=1em @R=0.8em {
        & \gate{H} & \ctrl{3} & \qw & \qw & \qw & \qw & \qw & \ctrl{3} & \gate{H} \\
        & \gate{S^\dagger} & \qw & \ctrl{2} & \qw & \qw & \qw & \ctrl{2} & \qw & \gate{S} \\
        & \gate{I} &\qw & \qw & \ctrl{1} & \qw & \ctrl{1} & \qw & \qw & \gate{I} \\
        \lstick{\ket{0}} & \qw & \targ & \targ & \targ & \gate{R_Z(2\theta)} & \targ & \targ & \targ & \qw 
    }
\end{array}
\]
\caption{Mixed Pauli rotations}
\end{table}
\todo{Lemmize this}

We will now collect these basic observations, along with an optimization that eliminates the ancilla qubit, in the following lemma.
\begin{lemma} \label{lem:pauli_rotations}
    Let $P$ be an $n$ qubit Pauli operator and $U_P$ the change of basis unitary from a product of $Z$ operators, i.e 
    \begin{equation}
        P = U_P \left(Z_1^{p_1} Z_2^{p_2} \ldots Z_n^{p_n} \right) U_P^\dagger,
    \end{equation}
    where each power $p_i$ is 0 or 1. The support of $P$, or the qubits in which $P$ acts nontrivially on, is denoted ${\rm supp}(P)$ and is the set of nonzero $p_i$. We denote the cardinality $|{\rm supp}(P)| = w$, as it is typically referred to as the weight of $P$, and let $s_w$ denote the largest index in supp$(P)$. The time evolution operator $e^{i P t}$ can be performed with $2(w-1)$ CNOT gates and one single qubit $Z$ rotation via the following identity
    \begin{equation}
        e^{i P t} = U_P \left(\prod_{i \in {\rm supp}(P) \setminus s_w} {\rm CNOT}(i, s_w) R_{Z_{s_w}}(t) \prod_{i \in {\rm supp}(P) \setminus s_w} {\rm CNOT}(i, s_w) \right) U_P^\dagger.
    \end{equation}
    This construction uses no additional ancilla qubits.
\end{lemma}
\begin{proof}
    We first note that 
    \begin{equation}
        e^{i P t} = \sum_{k = 0}^\infty \frac{(i t)^k}{k!} P^k = \sum_{k = 0}^\infty \frac{(i t)^k}{k!} (U_P \prod_i Z_i^{p_i} U_P^\dagger)^k = U_P \left(\sum_{k = 0}^\infty \frac{(i t)^k}{k!} ( \prod_i Z_i^{p_i})^k \right) U_P^\dagger = U_P e^{i \prod_i Z_i^{p_i} t} U_P^\dagger.
    \end{equation}
    This reduces our problem from arbitrary Pauli rotations to just Pauli $Z$ rotations. We now need to show that the CNOT sequence and single qubit $Z$ rotation perform arbitrary tensor product $Z$ rotations. Let CNOT$(i,j)$ be a controlled NOT gate with control qubit $i$ and target qubit $j$. Consider a basis state $\ket{a} = \ket{a_1}\ket{a_2}\ldots \ket{a_n}$, where each $a_i$ is 0 or 1. Let $\ket{s} = \ket{s_1} \ket{s_2} \ldots \ket{s_w}$ denote the basis states $a_i$ that are in the support of $P$. As CNOT$(1,2) \ket{b}\ket{c} = \ket{b} \ket{b \oplus c}$, where $b \oplus c$ is the addition of $b$ and $c$ mod 2, we have that the product
    \begin{equation}
        \prod_{i \in {\rm supp}(P) \setminus s_w} {\rm CNOT}(i, s_w) \ket{s} = \ket{s_1} \ldots \ket{s_{w-1}} \ket{s_1 \oplus s_2 \oplus \ldots \oplus s_w}
    \end{equation}
    stores the parity of the entire basis state in the last qubit. Applying a $Z$ rotation on the last qubit then yields the following
    \begin{align}
        R_{Z_{s_w}}(t) \ket{s_1} \ldots \ket{s_{w-1}} &= \ket{s_1} \ldots \ket{s_{w- 1}} \left(R_Z(t) \ket{s_1 \oplus \ldots \oplus s_w} \right) \\
        &= e^{i \bigoplus_{i = 1}^w s_i t} \ket{s_1} \ldots \ket{s_{w- 1}} \ket{s_1 \oplus \ldots \oplus s_w}.
    \end{align}
    Performing the same sequence of CNOT gates in reverse then ``uncomputes'' the parity
    \begin{align}
        \prod_{i \in {\rm supp}(P) \setminus s_w} {\rm CNOT}(i, s_w) e^{i \bigoplus_{i = 1}^w s_i t} \ket{s_1} \ldots \ket{s_{w- 1}} \ket{s_1 \oplus \ldots \oplus s_w} &= e^{i \bigoplus_{i = 1}^w s_i t} \ket{s_1} \ldots \ket{s_{w- 1}} \ket{s_w}.
    \end{align}
    As the circuit performs as desired on an arbitrary basis state, by linearity it extends to an arbitrary superposition.

    Since we just showed that 
    \begin{equation}
    \prod_{i \in {\rm supp}(P) \setminus s_w} {\rm CNOT}(i, s_w) R_{Z_{s_w}}(t) \prod_{i \in {\rm supp}(P) \setminus s_w} {\rm CNOT}(i, s_w) = e^{i \prod_i Z_i^{p_i} t}
    \end{equation}
    and the change of basis unitary $U_P$ from the $P$ basis to the computational $Z$ basis consist solely of tensor products of $H$ and $S$ we have therefore shown that $e^{i P t}$ can be implemented using single qubit unitaries and CNOT gates with no ancilla qubits.
\end{proof}

Lemma \ref{lem:pauli_rotations} serves as the basis for a class of simulation algorithms known as Pauli formulas.
We will introduce and prove two techniques for time-independent Hamiltonian simulation in this section, namely Trotter formulas and the randomized channel QDRIFT, as they serve as the basis for the optimizations that we introduce later in Chapter \ref{ch:composite_sims}. The first order Trotter formula was the first simulation algorithm and was developed by Lloyd \cite{lloyd1996universal}. The advantages of this algorithm is that it is straightforward, easy to implement, and requires no ancilla qubits. The downside is that analytically our bounds on the runtime of the algorithm scale as $O\left( L \frac{t^2}{\epsilon}\right)$ for the first order formula, which is significantly worse than the lower bound of $\Omega\left(t + \log \frac{1}{\epsilon} \right)$. This spurred the development of more sophisticated techniques for the Hamiltonian simulation problem, many of which require a different input model, namely a block-encoding, for the Hamiltonian than the Pauli decomposition we consider, leading to asymptotically optimal algorithms \cite{low2019hamiltonian} that utilize only a single additional ancilla qubit. However, many practitioners observed that in practice Trotter algorithms tended to drastically outperform their worst case analyses. The analysis of product formulas was improved to account for the commutation structure of the Hamiltonian in \cite{childs2021theory} and was shown to be superior to analytically ``optimal'' techniques for certain Hamiltonians. Recently improved analysis of Trotter formulas showed that entanglement can improve these error estimates, so progress is still being made in undestanding the performance of Trotter nearly 30 years later. 

The second method we will 


The first two methods we introduce are the first and second order Trotter formulas, which are also chronologically the first methods developed \cite{lloyd1996universal}. These are deterministic methods that simulate a Hamiltonian $H = \sum_{i = 1}^L h_i H_i$, where for simplicity we have pulled out the 
Now we will show how to build the simplest product formula: a first order Trotter decomposition. 
Let $H = \sum_{i = 1}^{L} h_i H_i$, where $H_i$ is a Pauli string. Our goal is to prove the following
\begin{equation}
    U_{\rm TS}^{(1)}(t) \coloneqq e^{i h_1 H_1 t}e^{i h_2 H_2 t} \ldots e^{i h_L H_L t} 
\end{equation}
and then eventually we want to prove the second order Trotter formula
\begin{equation}
    U_{\rm TS}^{(2)} = e^{i h_1 H_1 t/2} e^{i h_2 H_2 t/2} \ldots e^{i h_L H_L t / 2} e^{i h_L H_L t / 2} \ldots e^{i h_2 H_2 t/2} e^{i h_1 H_1 t/2}
\end{equation}


The next thing we have to discuss is the QDrift Channel. This channel is a randomized product formula, meaning that instead of visiting the terms in the Hamiltonian one by one, we will randomly choose a term from the Hamiltonian and simulate it. By repeating this process we can approximate the overall time evolution channel. As we are implementing a probabilistic application of a unitary time evolution we need to represent the algorithm as a quantum channel acting on density matrices
\begin{equation}
    \mathcal{U}_{\rm QD}(\rho; t) \coloneqq \sum_{i = 1}^L \frac{h_i}{\norm{h}} e^{-i H_i \tau} \rho e^{+i H_i \tau}.
\end{equation}

% Q: What is this thesis about!??@!??! Answer this with one sentence. Then extend to a paragraph. 

% A: This thesis is an algorithm for digital fault tolerant computers to prepare thermal input states. It uses techniques from classical algorithms, specifically Hamiltonian Monte Carlo (HMC), that prepare markov chain monte carlo (MCMC) states. 

% The central question of this thesis is how to prepare thermal input states for digital fault tolerant quantum computers using a minimal amount of ancilla overhead, just a single qubit. We assume access to 

% The central quest of this thesis is how to prepare thermal input states for digital fault tolerant quantum computers using the minimal amount of overhead ancillae needed, which is just a single qubit. We accomplish this quest by analyzing a quantum analog of the Hamiltonian Monte Carlo (HMC, also known as hybrid Monte Carlo) algorithm. 

% The central quest of this thesis is a proposed mechanism for quantum thermalization for arbitrary systems that can be simulated by quantum computers. 

% The central quest that started this thesis was to develop a quantum analog 


% This thesis is an attempt to understand a quantum analog of the Hamiltonian Monte Carlo (HMC) algorithm. If you are interested in the results of this experiment I will do my best to explain them starting from the beginning. This journey will involve an explanation of the original Metropolis-Hastings algorithm, the Hamiltonian modification that yields HMC, how to simulate weak interactions with an environment, and finally how to utilize these to prepare thermal states, the quantum version of the output of HMC. The last chapter of this thesis includes numerics that reinforce the analytic results. 

% Our starting point is the Metropolis-Hastings algorithm. This algorithm was developed to address the fundamental problem facing scientists of ``scale''. As physics offers the most accurate underlying theory of microscopic interactions, we start there. When learning physics, the most common teaching tools are small, toy problems. A block on a perfectly triangular incline plane. A ball attached to the end of a very long pendulum that is barely moved from it's resting point. Although these problems are not 100\% realistic, they offer great starting points to add more realistic features. Maybe curvature is added to the incline plane or the oscillator is damped. We can make these toy problems more realistic in this manner, and typically they can be solved via perturbative methods or other various approximations. The more challenging issue when making these toy problems more realistic is the problem of scale. We can solve a single mass and spring, but how do we solve $10^{-23}$ masses and springs all connected together? 

% This problem of scale leads to fundamentally different tools and techniques being used at various levels. The methods used by high energy theorists working ``closest to the metal'' are going to be radically different, but no more valid, than the techniques of climate scientists, which are different than cosmologists. This was first observed by Nobel laureate Paul Anderson with the philosophy ``More is Different'' \cite{moreIsDifferent}. One of the primary tools theorists have to address this difficulty of scale are classical computers. The reason computers allow us to transcend many orders of magnitude when solving problems is that they are simply much faster at basic arithmetic, namely floating point operations, than people. For example, at the time of writing the world record for the longest number memorized is 3260 digits memorized and recalled perfectly given an hour to commit the number to memory. A single Apple watch can store 700,000 equally long numbers and perform basic arithmetic on each one in less than a second. The sheer scale of exaflop supercomping ($10^{15}$ Floating Point OPerations) is difficult to comprehend or put in a human perspective. 

% One of the oldest and most studied algorithm for physicists, chemists, or material scientists to take advantage of the absurdly large computational power of classical compute clusters is the Metropolis-Hastings algorithm \cite{metropolis1953equation}. This algorithm is a general purpose tool that allows one to sample from thermal distributions of a given classical Hamiltonian, and as such has given scientists a computational lens to understanding the behavior of large systems. However, one of the downsides to the algorithm is that it exhibits ``random walk'' behavior, meaning it explores the state space in a diffusive manner, leading to a scaling of $D^2$ where $D$ is the dimension of your dataset. To avoid this random walk, better techniques have been proposed that take advantage of gradient information to mimic Hamiltonian time evolution which allows one to traverse larger distances before generating a sample, which leads to less correlation.

% On the physics side of the coin, these algorithms essentially prepare samples from the Boltzmann distribution $p_\beta (\vec{x}) = \frac{e^{-\beta H(\vec{x})}}{\int e^{-\beta H(\vec{x})} d\vec{x}}$. This is the generic distribution that describes the ``canonical'' ensemble, or the probability distribution that systems at a fixed temperature exhibit. This then allows us to estimate observables $O$ of systems at a given temperature $\beta$ as $\langle O \rangle = \int O(\vec{x}) p_\beta (\vec{x}) d\vec{x}$. As an example, if we would like to numerically explore what the average magnetization of a given compound is then the observable we are interested would be the average of all the component spins $O = \frac{1}{n} \sum_{i = 1}^n \hat{S}_i$. 

% From a physics perspective, we have a pretty good idea of when classical systems tend to thermalize, or when their state is very close to the thermal state. We now that when in contact with a large bath at inverse temperature $\beta$ in the long time limit as $t \to \infty$ we get the thermal state for the system. For quantum mechanics the picture is much less clear. There exists models that mimic weak interactions with a large, memoryless bath that lead to systems thermalizing. One example of this are the Davies Generators \cite{davies1974markovian} which can lead to thermalization for arbitrary systems (I think) in the infinite time, zero coupling limit. Further confusing the picture is whether one wants to study an open quantum system, in which the environment is only important because of the transitions it can provide for the system, or a closed quantum system, in which a large system only interacts with itself and no external transfer of energy is present. Our best understanding of whenever a closed system can appear thermalized to a small observable is the Eigenstate Thermalization Hypothesis (ETH), which works for Hamiltonians that appear sufficiently random but not for all Hamiltonians (hence the name Eigenstate Thermalization \emph{Hypothesis}, not Theorem). 

% This thesis is concerned with an intermediate regime for thermalization models. In the Davies Generator picture we are modeling a nearly infinite sized environment solely via the transitions it induces in the system and in the ETH picture we have no environment whatsoever. The thermalization model that we end up with has a very small environment, in our scenario a single qubit, that gets refreshed many times. This model is known as the Repeated Interactions (RI) model and is previously only studied for very small systems, namely 2 or 3 energy levels. In this thesis we will demonstrate how this model can be extended to an arbitrary non-degenerate system and the conditions dictating non-degeneracy are very weak and can most likely be lifted.

% We will work our way up to this main contribution. To do so, we will first explore how we can improve the main quantum subroutine used, time independent Hamiltonian simulation.
